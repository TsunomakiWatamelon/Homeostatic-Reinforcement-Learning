{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environments.base_env import HomeostaticEnvironment\n",
    "from environments.anticipatory_env import AnticipatoryEnvironment\n",
    "from models.qlearning import QLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test base_env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "État initial : tensor([90., 37.])\n",
      "État après manger : tensor([100.,  37.])\n",
      "Récompense : tensor(10.)\n",
      "État après refroidissement : tensor([100.,  35.])\n",
      "Récompense : tensor(-2.8284)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Définir les paramètres\n",
    "initial_state = [90, 37]  # Glucose = 90, Température = 37\n",
    "setpoints = [100, 37]  # Setpoints pour le glucose et la température\n",
    "weights = [1, 2]  # Importance relative : température plus critique\n",
    "exponents = [2, 2]  # Non-linéarité pour les calculs de drive\n",
    "effects = {\n",
    "    \"eat\": [10, 0],  # Manger augmente le glucose de 10\n",
    "    \"cool_down\": [0, -2]  # Se refroidir réduit la température de 2\n",
    "}\n",
    "\n",
    "# Instancier l'environnement\n",
    "env = HomeostaticEnvironment(H=initial_state, setpoints=setpoints, weights=weights, exponents=exponents, effects=effects)\n",
    "\n",
    "# Test de l'environnement\n",
    "print(\"État initial :\", env.state)\n",
    "\n",
    "# Effectuer une action (\"eat\")\n",
    "state, reward,_,_ = env.step(\"eat\")\n",
    "print(\"État après manger :\", state)\n",
    "print(\"Récompense :\", reward)\n",
    "\n",
    "# Effectuer une autre action (\"cool_down\")\n",
    "state, reward,_,_ = env.step(\"cool_down\")\n",
    "print(\"État après refroidissement :\", state)\n",
    "print(\"Récompense :\", reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Experience Anticipation avec QLearning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "state_size = 1  # la température\n",
    "action_size = 2  # Actions : [0 = aucune réponse, 1 = réponse anticipatoire]\n",
    "alpha = 0.1\n",
    "gamma = 0.99\n",
    "epsilon = 0.1\n",
    "\n",
    "# Instancier le modèle Q-learning\n",
    "agent = QLearning(state_size=state_size, action_size=action_size, alpha=alpha, gamma=gamma, epsilon=epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des paramètres de l'environnement\n",
    "initial_state = torch.tensor([37.0])  # Température corporelle initiale\n",
    "setpoints = torch.tensor([37.0])  # Température optimale\n",
    "weights = torch.tensor([1.0])  # Importance de la température\n",
    "exponents = [2, 2]  # Non-linéarité\n",
    "effects = {\n",
    "    \"anticipate\": torch.tensor([0.5]),  # Augmentation légère de la température\n",
    "    \"injection\": torch.tensor([-1.5]),  # Diminution importante de la température\n",
    "}\n",
    "signal_timesteps = [10, 20, 30]  # Moments où un signal est donné avant l'injection\n",
    "\n",
    "# Instanciation de l'environnement\n",
    "env = AnticipatoryEnvironment(\n",
    "    H=initial_state,\n",
    "    setpoints=setpoints,\n",
    "    weights=weights,\n",
    "    exponents=exponents,\n",
    "    effects=effects,\n",
    "    signal_timesteps=signal_timesteps,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
